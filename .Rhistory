#This sends the urls to the Open Data Science Toolkit geocoder and returns lat, lon, address, and type
geocoder <- function(x){
return <- GET(x) %>% read_html %>% html_text %>% fromJSON()
if (return$status == "OK"){
goods <- as.data.frame(cbind(return$results$geometry$location$lat, return$results$geometry$location$lng, paste0(return$results$address_components[[1]]$short_name, sep = " ", collapse = ""), return$results$geometry$location_typ))
colnames(goods) <- c("Lat", "Lon", "Address", "Type")
} else {
goods <- "No Results"
}
return(goods)
}
urls <- lapply(x, urlgetter)
df <- lapply(urls, geocoder)
return(df)
}
shityeah <- alsgeocoder(addresses)
shityeah
addresses <- mv[-31,]$match_address
shityeah <- alsgeocoder(addresses)
shityeah
alsgeocoder <- function(addresses){
#This creates urls from the input addresses
urlgetter <- function(x){
str <- gsub(" ", "+", x)
togc <- paste0("http://www.datasciencetoolkit.org/maps/api/geocode/json?sensor=false&address=", str)
return(togc)
}
#This sends the urls to the Open Data Science Toolkit geocoder and returns lat, lon, address, and type
geocoder <- function(x){
return <- GET(x) %>% read_html %>% html_text %>% fromJSON()
if (return$status == "OK"){
results <- as.data.frame(cbind(return$results$geometry$location$lat, return$results$geometry$location$lng, paste0(return$results$address_components[[1]]$short_name, sep = " ", collapse = ""), return$results$geometry$location_typ))
colnames(goods) <- c("Lat", "Lon", "Address", "Type")
} else {
results <- "No Results"
}
return(results)
}
urls <- lapply(addresses, urlgetter)
df <- lapply(urls, geocoder)
return(df)
}
addressez <- mv[-31,]$match_address
shityeah <- alsgeocoder(addressez)
alsgeocoder <- function(x){
#This creates urls from the input addresses
urlgetter <- function(x){
str <- gsub(" ", "+", x)
togc <- paste0("http://www.datasciencetoolkit.org/maps/api/geocode/json?sensor=false&address=", str)
return(togc)
}
#This sends the urls to the Open Data Science Toolkit geocoder and returns lat, lon, address, and type
geocoder <- function(){
return <- GET(x) %>% read_html %>% html_text %>% fromJSON()
if (return$status == "OK"){
results <- as.data.frame(cbind(return$results$geometry$location$lat, return$results$geometry$location$lng, paste0(return$results$address_components[[1]]$short_name, sep = " ", collapse = ""), return$results$geometry$location_typ))
colnames(goods) <- c("Lat", "Lon", "Address", "Type")
} else {
results <- "No Results"
}
return(results)
}
urls <- lapply(x, urlgetter)
df <- lapply(urls, geocoder)
return(df)
}
shityeah <- alsgeocoder(addresses)
shityeah <- alsgeocoder(addresses)
alsgeocoder <- function(x){
#This creates urls from the input addresses
urlgetter <- function(x){
str <- gsub(" ", "+", x)
togc <- paste0("http://www.datasciencetoolkit.org/maps/api/geocode/json?sensor=false&address=", str)
return(togc)
}
#This sends the urls to the Open Data Science Toolkit geocoder and returns lat, lon, address, and type
geocoder <- function(){
return <- GET(x) %>% read_html %>% html_text %>% fromJSON()
if (return$status == "OK"){
results <- as.data.frame(cbind(return$results$geometry$location$lat, return$results$geometry$location$lng, paste0(return$results$address_components[[1]]$short_name, sep = " ", collapse = ""), return$results$geometry$location_typ))
colnames(goods) <- c("Lat", "Lon", "Address", "Type")
} else {
results <- "No Results"
}
return(results)
}
urls <- lapply(x, urlgetter)
df <- lapply(urls, geocoder)
return(df)
}
shityeah <- alsgeocoder(addresses)
geocoder <- function(){
return <- GET(x) %>% read_html %>% html_text %>% fromJSON()
if (return$status == "OK"){
results <- as.data.frame(cbind(return$results$geometry$location$lat, return$results$geometry$location$lng, paste0(return$results$address_components[[1]]$short_name, sep = " ", collapse = ""), return$results$geometry$location_typ))
colnames(goods) <- c("Lat", "Lon", "Address", "Type")
} else {
results <- "No Results"
}
return(results)
}
urls <- lapply(x, urlgetter)
df <- lapply(urls, geocoder)
alsgeocoder <- function(x){
#This creates urls from the input addresses
urlgetter <- function(x){
str <- gsub(" ", "+", x)
togc <- paste0("http://www.datasciencetoolkit.org/maps/api/geocode/json?sensor=false&address=", str)
return(togc)
}
#This sends the urls to the Open Data Science Toolkit geocoder and returns lat, lon, address, and type
geocoder <- function(x){
return <- GET(x) %>% read_html %>% html_text %>% fromJSON()
if (return$status == "OK"){
results <- as.data.frame(cbind(return$results$geometry$location$lat, return$results$geometry$location$lng, paste0(return$results$address_components[[1]]$short_name, sep = " ", collapse = ""), return$results$geometry$location_typ))
colnames(goods) <- c("Lat", "Lon", "Address", "Type")
} else {
results <- "No Results"
}
return(results)
}
urls <- lapply(x, urlgetter)
df <- lapply(urls, geocoder)
return(df)
}
shityeah <- alsgeocoder(addresses)
alsgeocoder <- function(x){
#This creates urls from the input addresses
urlgetter <- function(x){
str <- gsub(" ", "+", x)
togc <- paste0("http://www.datasciencetoolkit.org/maps/api/geocode/json?sensor=false&address=", str)
return(togc)
}
#This sends the urls to the Open Data Science Toolkit geocoder and returns lat, lon, address, and type
geocoder <- function(x){
return <- GET(x) %>% read_html %>% html_text %>% fromJSON()
if (return$status == "OK"){
results <- as.data.frame(cbind(return$results$geometry$location$lat, return$results$geometry$location$lng, paste0(return$results$address_components[[1]]$short_name, sep = " ", collapse = ""), return$results$geometry$location_typ))
colnames(results) <- c("Lat", "Lon", "Address", "Type")
} else {
results <- "No Results"
}
return(results)
}
urls <- lapply(x, urlgetter)
df <- lapply(urls, geocoder)
return(df)
}
shityeah <- alsgeocoder(addresses)
alsgeocoder <- function(x){
#This creates urls from the input addresses
urlgetter <- function(x){
str <- gsub(" ", "+", x)
togc <- paste0("http://www.datasciencetoolkit.org/maps/api/geocode/json?sensor=false&address=", str)
return(togc)
}
#This sends the urls to the Open Data Science Toolkit geocoder and returns lat, lon, address, and type
geocoder <- function(x){
return <- x %>% read_html %>% html_text %>% fromJSON()
if (return$status == "OK"){
results <- as.data.frame(cbind(return$results$geometry$location$lat, return$results$geometry$location$lng, paste0(return$results$address_components[[1]]$short_name, sep = " ", collapse = ""), return$results$geometry$location_typ))
colnames(results) <- c("Lat", "Lon", "Address", "Type")
} else {
results <- "No Results"
}
return(results)
}
urls <- lapply(x, urlgetter)
df <- lapply(urls, geocoder)
return(df)
}
shityeah <- alsgeocoder(addresses)
View(shityeah)
rbind(shityeah)
lapply(shityeah, rbind)
chkers <- lapply(shityeah, rbind)
lapply
View(chkers)
shityeah <- alsgeocoder(addresses)
alsgeocoder <- function(x){
#This creates urls from the input addresses
urlgetter <- function(x){
str <- gsub(" ", "+", x)
togc <- paste0("http://www.datasciencetoolkit.org/maps/api/geocode/json?sensor=false&address=", str)
return(togc)
}
#This sends the urls to the Open Data Science Toolkit geocoder and returns lat, lon, address, and type
geocoder <- function(x){
return <- x %>% read_html() %>% html_text() %>% fromJSON()
if (return$status == "OK"){
results <- as.data.frame(cbind(return$results$geometry$location$lat, return$results$geometry$location$lng, paste0(return$results$address_components[[1]]$short_name, sep = " ", collapse = ""), return$results$geometry$location_typ))
colnames(results) <- c("Lat", "Lon", "Address", "Type")
} else {
results <- "No Results"
}
return(results)
}
urls <- lapply(x, urlgetter)
df <- lapply(urls, geocoder)
return(df)
}
shityeah <- alsgeocoder(addresses)
library(rvest)
library(jsonlite)
library(purrr)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
cor.matrix<-function(x,data=NA){
# panel.hist function adds the histogram
panel.hist <- function(x, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(usr[1:2], 0, 1.5) )
h <- hist(x, plot = FALSE)
breaks <- h$breaks; nB <- length(breaks)
y <- h$counts; y <- y/max(y)
rect(breaks[-nB], 0, breaks[-1], y, col="cyan", ...)
box()
}
panel.cor <- function(x, y, digits=2, prefix="", cex.cor)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(0, 1, 0, 1))
r <- abs(cor(x, y,method="spearman"))
txt <- format(c(r, 0.123456789), digits=digits)[1]
txt <- paste(prefix, txt, sep="")
if(missing(cex.cor)) cex <- 0.8/strwidth(txt)
text(0.5, 0.5, txt, cex = cex * r)
}
if (class(x)=="formula"){
x<-model.frame(x,data=data)
}
pairs(x,lower.panel=panel.smooth,upper.panel=panel.cor,diag.panel=panel.hist,
cex.labels = 1, font.labels=2)
}
cbg <- readOGR("Energy_Burden/Metro_EnergyBurden_11817.shp")
require(dplyr)
require(foreign)
require(rpostgis)
require(RPostgreSQL)
require(sp)
require(spdep)
require(rgeos)
require(leaflet)
require(car)
require(plotly)
require(latticeExtra)
require(rgdal)
options(stringsAsFactors = F)
setwd("/home/atrusty/SUPR/Energy_Research/Energy_Burden/SR_Transfer/")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
cor.matrix<-function(x,data=NA){
# panel.hist function adds the histogram
panel.hist <- function(x, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(usr[1:2], 0, 1.5) )
h <- hist(x, plot = FALSE)
breaks <- h$breaks; nB <- length(breaks)
y <- h$counts; y <- y/max(y)
rect(breaks[-nB], 0, breaks[-1], y, col="cyan", ...)
box()
}
panel.cor <- function(x, y, digits=2, prefix="", cex.cor)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(0, 1, 0, 1))
r <- abs(cor(x, y,method="spearman"))
txt <- format(c(r, 0.123456789), digits=digits)[1]
txt <- paste(prefix, txt, sep="")
if(missing(cex.cor)) cex <- 0.8/strwidth(txt)
text(0.5, 0.5, txt, cex = cex * r)
}
if (class(x)=="formula"){
x<-model.frame(x,data=data)
}
pairs(x,lower.panel=panel.smooth,upper.panel=panel.cor,diag.panel=panel.hist,
cex.labels = 1, font.labels=2)
}
cbg <- readOGR("Energy_Burden/Metro_EnergyBurden_11817.shp")
#Calculate density and remove the lowest density block groups
cbg$cbg_area <- sapply(slot(cbg, "polygons"), slot, "area") #Create an area column
cbg <- subset(cbg, cbg$cbg_area < 5.0e+07 & cbg$cbg_area > 1e+06) #visually removed the large and very small block groups
cbg <- subset(cbg, cbg$sfr_nt > 40) # Subset CBGs with less than 40 SFR (As Chang et al did)
#Impute Medians
# There Shouldn't be many NA's
medePuter <- function(x){
x<-as.numeric(as.character(x)) #first convert each column into numeric if it is from factor
x[is.na(x)] =median(x, na.rm=TRUE) #convert the item with NA to median value from the column
x #display the column
}
cbg@data <- as.data.frame(apply(cbg@data,2,medePuter)) #Imputes medians for all of the missing independent variables
vars<-c("bldgsqft", "yearbuilt", "Avg_HHSize","H_Units", "MHI", "OOHU", "GT25_LTHS","GT25_GTBA", "Pop_Under1", "Pop_65Over", "Pop_White", "Pop_Black", "Pop_Hisp", "gis_acres", "mfr_n", "u_tot")
par(mfrow=c(3,3))
#Making plots for all variables:
invisible(lapply(c("TOTkwh15", vars[1:8]), function(x){
hist(cbg@data[,x],main=paste0(x),xlab=x,freq=F)
lines(density(cbg@data[,x],bw=sd(cbg@data[,x])),col="red",lwd=2)
}))
par(mfrow=c(3,3))
#Making plots for all variables:
invisible(lapply(c("TOTkwh15", vars[9:16]), function(x){
hist(cbg@data[,x],main=paste0(x),xlab=x,freq=F)
lines(density(cbg@data[,x],bw=sd(cbg@data[,x])),col="red",lwd=2)
}))
cbg <- subset(cbg, cbg$yearbuilt > 1800) #Anything with an average age of 1800 or older probably isn't accurate..
cbg$log_bldgsqft <- log(1+cbg$bldgsqft)
cbg$log_GT25_LTHS <- log(1+cbg$GT25_LTHS)
cbg$log_GT25_GTBA<- log(1+cbg$GT25_GTBA)
cbg$log_Under18 <- log(1+cbg$Pop_Under1)
cbg$log_Over65 <- log(1+cbg$Pop_65Over)
cbg$log_Black  <- log(1+cbg$Pop_Black)
cbg$log_Hisp <- log(1+cbg$Pop_Hisp)
cbg$log_acres <- log(1+cbg$gis_acres)
cbg$log_mfrn <- log(1+cbg$mfr_n)
bpvars <- c("log_bldgsqft"
, "log_GT25_LTHS"
, "log_GT25_LTHS"
, "log_Under18"
, "log_Over65"
, "log_Black"
, "log_Hisp"
, "log_acres"
, "log_mfrn")
par(mfrow=c(3,4))
invisible(lapply(bpvars, function(x){
boxplot(cbg@data[,x],main=paste0(x),xlab=x)
}))
par(mfrow=c(3,4))
invisible(lapply(bpvars, function(x){
boxplot(cbg@data[,x],main=paste0(x),xlab=x)
}))
cbg_redu <- subset(cbg, cbg$bldgsqft < 3000)
par(mfrow=c(3,4))
invisible(lapply(bpvars, function(x){
boxplot(cbg_redu@data[,x],main=paste0(x),xlab=x)
}))
cbg_redu <- subset(cbg_redu, cbg_redu$u_tot > 300 & cbg_redu$u_tot < 1300) # Block groups within similar range of utility samples
par(mfrow = c(3,2))
par(mfrow = c(3,2))
boxplot(cbg$u_tot, main = "Outliers for # of Utility Units (UCI Count)", ylab = "Count of Utilities / Census BG")
hist(cbg$u_tot, main = "Utility Units Histogram")
boxplot(cbg_redu$u_tot, main = "Boxplot After Outlier Removal", ylab = "Count of Utilities / Census BG")
hist(cbg_redu$u_tot, main = "Utility Units Histogram after Removal")
boxplot(cbg$bldgsqft, main = "Building SqFt Distribution Before Outlier Removal")
boxplot(cbg_redu$bldgsqft, main = "Building SqFt Distribtion After Outlier Removal")
vars2<-c("log_bldgsqft", "Avg_HHSize","H_Units", "MHI", "OOHU", "log_GT25_LTHS","log_GT25_GTBA", "log_Under18", "log_Over65", "Pop_White", "log_Black", "log_Hisp", "log_acres", "log_mfrn")
#Assessing Correlation:
tl_cor<-cor(cbg_redu@data[,c("TOTkwh15",vars2)])[,1]
tl_cor<-data.frame(Variable=names(tl_cor),r = as.vector(tl_cor));tl_cor
cbg_redu <- cbg_redu[,c("TOTkwh15", "log_bldgsqft", "yearbuilt", "Avg_HHSize", "MHI", "OOHU", "log_GT25_LTHS","log_GT25_GTBA", "log_Under18", "log_Over65", "Pop_White", "log_Black", "log_Hisp", "log_acres", "log_mfrn")]
finvars <- c("log_bldgsqft", "yearbuilt", "Avg_HHSize", "MHI", "OOHU", "log_GT25_LTHS","log_GT25_GTBA", "log_Under18", "log_Over65", "Pop_White", "log_Black", "log_Hisp", "log_acres", "log_mfrn")
#Making plots for all variables:
invisible(lapply(c("TOTkwh15", finvars), function(x) {
plot(cbg_redu@data$TOTkwh15 ~ cbg_redu@data[,x],main=paste0("TOTkwh15 vs ", x),xlab=x,ylab="Total kWh")
}))
par(mfrow=c(4,4))
#Making plots for all variables:
invisible(lapply(c("TOTkwh15", finvars), function(x) {
plot(cbg_redu@data$TOTkwh15 ~ cbg_redu@data[,x],main=paste0("TOTkwh15 vs ", x),xlab=x,ylab="Total kWh")
}))
par(mfrow=c(2,4))
#Making plots for all variables:
invisible(lapply(c("TOTkwh15", finvars[1,8:14]), function(x) {
plot(cbg_redu@data$TOTkwh15 ~ cbg_redu@data[,x],main=paste0("TOTkwh15 vs ", x),xlab=x,ylab="Total kWh")
}))
par(mfrow=c(3,4))
#Making plots for all variables:
invisible(lapply(c("TOTkwh15", finvars[1,8:14]), function(x) {
plot(cbg_redu@data$TOTkwh15 ~ cbg_redu@data[,x],main=paste0("TOTkwh15 vs ", x),xlab=x,ylab="Total kWh")
}))
par(mfrow=c(3,4))
#Making plots for all variables:
invisible(lapply(c("TOTkwh15", finvars[8:14]), function(x) {
plot(cbg_redu@data$TOTkwh15 ~ cbg_redu@data[,x],main=paste0("TOTkwh15 vs ", x),xlab=x,ylab="Total kWh")
}))
par(mfrow=c(2,4))
#Making plots for all variables:
invisible(lapply(c("TOTkwh15", finvars[8:14]), function(x) {
plot(cbg_redu@data$TOTkwh15 ~ cbg_redu@data[,x],main=paste0("TOTkwh15 vs ", x),xlab=x,ylab="Total kWh")
}))
#Making plots for all variables:
invisible(lapply(c("TOTkwh15", finvars[1:7]), function(x) {
plot(cbg_redu@data$TOTkwh15 ~ cbg_redu@data[,x],main=paste0("TOTkwh15 vs ", x),xlab=x,ylab="Total kWh")
}))
par(mfrow=c(2,4))
#Making plots for all variables:
invisible(lapply(c("TOTkwh15", finvars[1:7]), function(x) {
plot(cbg_redu@data$TOTkwh15 ~ cbg_redu@data[,x],main=paste0("TOTkwh15 vs ", x),xlab=x,ylab="Total kWh")
}))
finvars <- c("log_bldgsqft", "yearbuilt", "Avg_HHSize", "MHI", "OOHU", "log_GT25_LTHS","log_GT25_GTBA", "log_Under18", "log_Over65", "Pop_White", "log_Black", "log_Hisp", "log_acres", "log_mfrn")
par(mfrow=c(2,4))
#Making plots for all variables:
invisible(lapply(c("TOTkwh15", finvars[1:7]), function(x) {
plot(cbg_redu@data$TOTkwh15 ~ cbg_redu@data[,x],main=paste0("TOTkwh15 vs ", x),xlab=x,ylab="Total kWh")
}))
tl_point<-gCentroid(cbg_redu,byid=T)
nb <-  knn2nb(knearneigh(tl_point, k = 5))
nb_lines<-spTransform(nb2lines(nb, proj4string = cbg_redu@proj4string, coords = coordinates(tl_point)), CRS("+proj=longlat +datum=WGS84"))
leaflet() %>% addProviderTiles(providers$OpenStreetMap) %>%
addCircleMarkers(data=spTransform(tl_point,CRS("+proj=longlat +datum=WGS84"))
,weight=2
,color="black"
,fillColor = "grey"
,fillOpacity = 0.15
,opacity= 1
,radius=4) %>%
addPolylines(data=nb_lines,color="red",weight=2)
#Creating Spatial lag and plotting
cbg_redu$resid <- sfmod.redu$residuals
sfmod.redu <- lm(TOTkwh15~
+ I(2017 - yearbuilt)
+ log_bldgsqft
+ MHI
+ log_GT25_LTHS
+ log_Over65
+ log_acres
+ log_mfrn, data= cbg_redu)
summary(sfmod.redu)
car::vif(sfmod.redu)
#Creating Spatial lag and plotting
cbg_redu$resid <- sfmod.redu$residuals
resnb <- sapply(nb, function(x) mean(sfmod.redu$residuals[x]))
plot(sfmod.redu$residuals, resnb, xlab ='Residuals', ylab = 'Mean of adjacent residuals')
text(5000,-2500,paste0("Correlation: ", round(cor(cbg_redu$resid, resnb), 4)), col="red")
sem <- errorsarlm(TOTkwh15~
+ I(2017 - yearbuilt)
+ log_bldgsqft
+ MHI
+ log_GT25_LTHS
+ log_Over65
+ log_acres
+ log_mfrn, data= cbg_redu, weights)
#Creating Spatial lag and plotting
cbg_redu$resid <- sfmod.redu$residuals
resnb <- sapply(nb, function(x) mean(sfmod.redu$residuals[x]))
plot(sfmod.redu$residuals, resnb, xlab ='Residuals', ylab = 'Mean of adjacent residuals')
text(5000,-2500,paste0("Correlation: ", round(cor(cbg_redu$resid, resnb), 4)), col="red")
weights <- nb2listw(nb)
moran.mc(cbg_redu$resid, weights, 999)
lm.LMtests(sfmod.redu, listw=weights)
sem <- errorsarlm(TOTkwh15~
+ I(2017 - yearbuilt)
+ log_bldgsqft
+ MHI
+ log_GT25_LTHS
+ log_Over65
+ log_acres
+ log_mfrn, data= cbg_redu, weights)
summary(sem)
plot(sem$fitted.values~cbg_redu$TOTkwh15, xlab = "Observed 2015 Total kWh Values", ylab = "Fitted SEM Values")
abline(lm(sem$fitted.values~cbg_redu$TOTkwh15), col="red", lwd=2)
text(15000,25000,paste0("R-squared: ", round(summary(lm(sem$fitted.values~cbg_redu$TOTkwh15))$adj.r.square,4)))
## Testing Normality in Residuals
shapiro.test(sem$residuals) #indicates residuals are not normaly distributed.
#Check Qnorm
par(mfrow=c(1,2))
hist(sem$residuals, breaks=20, main = "Spatial Error Model - Residuals", xlab = "Residuals", freq = F)
qqnorm(sem$residuals)
#Assessing heteroskedasticity:
plot(sem$residuals~sem$fitted.values, main = "Fitted Values vs. Residuals", xlab = "Fitted (Estimated) Total kwh", ylab = "Residuals", pch = 19)
#Assessing heteroskedasticity:
plot(sem$residuals~sem$fitted.values, main = "Fitted Values vs. Residuals", xlab = "Fitted (Estimated) Total kwh", ylab = "Residuals", pch = 19)
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("/home/atrusty/alectrusty.github.io/")
#render your sweet site.
rmarkdown::render_site()
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("/home/atrusty/alectrusty.github.io/")
#render your sweet site.
rmarkdown::render_site()
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("/home/atrusty/alectrusty.github.io/")
#render your sweet site.
rmarkdown::render_site()
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("/home/atrusty/alectrusty.github.io/")
#render your sweet site.
rmarkdown::render_site()
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("/home/atrusty/alectrusty.github.io/")
#render your sweet site.
rmarkdown::render_site()
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("/home/atrusty/alectrusty.github.io/")
#render your sweet site.
rmarkdown::render_site()
#Set our working directory.
#This helps avoid confusion if our working directory is
#not our site because of other projects we were
#working on at the time.
setwd("/home/atrusty/alectrusty.github.io/")
#render your sweet site.
rmarkdown::render_site()
